<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>实验室成员</title>
    <url>/about/index.html</url>
    <content><![CDATA[<h2 id="导师"><a href="#导师" class="headerlink" title="导师"></a>导师</h2><table border="0">
  <tr>
    <td>
        <img align="middle" src="/about/index/sunjun.png" width="150" height="150">
    </td>
    <td>
        孙俊 教授<br>
        北京大学王选计算机研究所<br>
        颐和园路5号, 北京市海淀区, 100871<br>
        Email: jsun@pku.edu.cn<br><br>
    </td>
  </tr>
</table>

<h2 id="博士"><a href="#博士" class="headerlink" title="博士"></a>博士</h2><p>尚明宇 <a href="mailto:mingyu.shang@pku.edu.cn">mingyu.shang@pku.edu.cn</a><br>黄志杰 <a href="mailto:zhijiehuang@pku.edu.cn">zhijiehuang@pku.edu.cn</a><br>郭晓鹏 <a href="mailto:xiaopeng.guo@stu.pku.edu.cn">xiaopeng.guo@stu.pku.edu.cn</a><br>树茂菁 <a href="mailto:shumaojing@pku.edu.cn">shumaojing@pku.edu.cn</a><br>赵辉 <a href="mailto:hui.zhao@stu.pku.edu.cn">hui.zhao@stu.pku.edu.cn</a><br>陈润恺 <a href="mailto:chenrunkai@pku.edu.cn">chenrunkai@pku.edu.cn</a><br>王延泽 <a href="mailto:king.donmn@gmail.com">king.donmn@gmail.com</a></p>
<h2 id="硕士"><a href="#硕士" class="headerlink" title="硕士"></a>硕士</h2><p>李云畅 <a href="mailto:liyunchang@pku.edu.cn">liyunchang@pku.edu.cn</a><br>高洁 <a href="mailto:gaojie2018@pku.edu.cn">gaojie2018@pku.edu.cn</a></p>
<h2 id="毕业生"><a href="#毕业生" class="headerlink" title="毕业生"></a>毕业生</h2><h3 id="硕士-1"><a href="#硕士-1" class="headerlink" title="硕士"></a>硕士</h3><p>2016级 张樱凡 郑羽珊<br>2015级 冯伟伦 靖奇 徐鹏 雷文雨<br>2014级 王杰西 林镇安 钟鸣<br>2013级 范英明 张奇<br>2012级 周燕萍<br>2011级 刘森<br>2010级 颜乐驹</p>
<h3 id="博士-1"><a href="#博士-1" class="headerlink" title="博士"></a>博士</h3><p>2014级 陈科吉<br>2012级 段一舟<br>2011级 孟胜彬</p>
]]></content>
  </entry>
  <entry>
    <title>新闻动态</title>
    <url>/activities/index.html</url>
    <content><![CDATA[<div style="overflow: scroll; overflow-x: hidden; overflow-y: hidden">
<table border="0">
<tbody>
  <tr>
    <td style="text-align: center; vertical-align: middle !important; height: 150px">
    <img src="/activities/index/jucan20210926.jpg" style="width: 270px;height: 150px">
    <a href="2021-09-26.html"><strong>2021-09-26 聚餐</strong></a>
    </td>
    <td style="text-align: center; vertical-align: middle !important; height: 150px">
    <img src="/activities/index/xiaopeng_mm1.png" style="width: 270px;height: 150px">
    <a href="xiaopeng_mm1.html"><strong>2021-07-03 [MM]郭晓鹏</strong></a>
    </td>
    <td style="text-align: center; vertical-align: middle !important; height: 150px">
    <img src="/activities/index/zhijie_tcsvt1.png" style="width: 270px;height: 150px">
    <a href="zhijie_tcsvt1.html"><strong>2021-06-15 [TCSVT]黄志杰</strong></a>
    </td>
    <td style="text-align: center; vertical-align: middle !important; height: 150px">
    <img src="/activities/index/jucan20210613.jpg" style="width: 270px;height: 150px">
    <a href="2021-06-13.html"><strong>2021-06-13 聚餐</strong></a>
    </td>
  </tr>
  <tr>
    <td style="text-align: center; vertical-align: middle !important; height: 150px">
    <img src="/activities/index/zhijie_tip1.png" style="width: 270px;height: 150px">
    <a href="zhijie_tip1.html"><strong>2021-06-03 [TIP]黄志杰</strong></a>
    </td>
  </tr>
</tbody>
</table>
</div>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/activities/2021-06-13.html</url>
    <content><![CDATA[<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
<meta name="generator" content="Hexo 4.2.1"></head>
<body>
<h3>实验室聚餐 阿西娅餐厅</h3>
<img src="/activities/2021-06-13.htm/jucan20210613.jpg" style="width: 500px;">
祝贺硕士研究生高洁、本科实习生赵东顺利毕业！
</body>
</html>]]></content>
  </entry>
  <entry>
    <title>编解码器下载</title>
    <url>/download/index.html</url>
    <content><![CDATA[<hr>
<h3 id="Lentoid-Windows版H-265-HEVC解码器"><a href="#Lentoid-Windows版H-265-HEVC解码器" class="headerlink" title="Lentoid Windows版H.265/HEVC解码器"></a>Lentoid Windows版H.265/HEVC解码器</h3><p><strong>最新版本：</strong>r6555 &emsp; <strong>发布日期：</strong>2018/09/05 &emsp; <strong>软件大小：</strong>2.73 MB<br><strong>版本说明：</strong>1、该版本仅供个人测试HEVC解码速度使用；2、全面兼容HM12.0；3、容错功能，对于HEVC码流错误能够进行最大化的友好处理；4.支持解码10-bit HEVC视频（但仍以8-bit渲染输出）；5.包含播放器插件<br><strong>配置要求：</strong>支持系统WinServer 2003/2008, Win XP/Vista, Win7/Win8 <span style="float:right"><a href="windows.tar">下载 ⬇</a></span></p>
<hr>
<h3 id="Lentoid-Linux版H-265-HEVC解码器"><a href="#Lentoid-Linux版H-265-HEVC解码器" class="headerlink" title="Lentoid Linux版H.265/HEVC解码器"></a>Lentoid Linux版H.265/HEVC解码器</h3><p>最新版本：r6555 &emsp; 发布日期：2018/09/03 &emsp; 软件大小：580 KB<br>版本说明：1、该版本仅供个人测试HEVC解码速度使用；2、全面兼容HM12.0；3、容错功能，对于HEVC码流错误能够进行最大化的友好处理；4.支持解码10-bit          HEVC视频（但仍以8-bit渲染输出）<br>配置要求：支持系统Centos, Ubuntu等 <span style="float:right"><a href="linux.tar">下载 ⬇</a></span></p>
<hr>
<h3 id="Lentoid-Android版H-265-HEVC解码器"><a href="#Lentoid-Android版H-265-HEVC解码器" class="headerlink" title="Lentoid Android版H.265/HEVC解码器"></a>Lentoid Android版H.265/HEVC解码器</h3><p>最新版本：r6555     发布日期：2018/09/03     软件大小：1.34 MB<br>版本说明：1、该版本仅供演示Android设备的HEVC解码使用；2、支持.hevc/.hm10/.hm91/.bin/.bit格式HEVC码流；3、容错功能，对于HEVC码流错误能够        进行最大化的友好处理；4、默认线程数为单线程，可通过更改设置开启多线程解码<br>配置要求：480x320以上分辨率；采用ARMv7架构和NEON多媒体指令集的CPU，或者采用x86架构和SSEx多媒体指令集的CPU；支持Android 2.3或更高版本 <span style="float:right"><a href="android.tar">下载 ⬇</a></span> <span style="float:right">&nbsp;&nbsp;&nbsp;&nbsp;</span> <span style="float:right"><a href="android_apk.tar">下载apk ⬇</a></span></p>
<hr>
<h3 id="Lentoid-iOS版H-265-HEVC解码器"><a href="#Lentoid-iOS版H-265-HEVC解码器" class="headerlink" title="Lentoid iOS版H.265/HEVC解码器"></a>Lentoid iOS版H.265/HEVC解码器</h3><p>最新版本：r6555     发布日期：2018/09/03     软件大小：3.29 MB<br>版本说明：1、该版本仅供演示iOS设备的HEVC解码使用；2、支持.hevc/.hm10/.hm91/.bin/.bit格式HEVC码流；3、增加了对ARMv7s架构的支持；4、容错         功能，对于HEVC码流错误能够进行最大化的友好处理<br>配置要求：兼容iPhone和iPad，需要iOS 6.0或更高版本 <span style="float:right"><a href="ios.tar">下载 ⬇</a></span></p>
<hr>
<h3 id="Lentoid-Windows版H-265-HEVC编码器"><a href="#Lentoid-Windows版H-265-HEVC编码器" class="headerlink" title="Lentoid Windows版H.265/HEVC编码器"></a>Lentoid Windows版H.265/HEVC编码器</h3><p>最新版本：2.8 r6740版本     发布日期：2019/02/26     软件大小：1.30 MB<br>版本说明：1、该版本仅供测试使用，可编码的帧数有上限；2、支持多种码率控制算法，支持4Kx2K视频编码<br>配置要求：2G以上内存；需要支持AVX2指令集；支持系统WinServer 2003/2008, Win XP/Vista,<br>        Win7/ Win8/ Win10 <span style="float:right"><a href="lentenc_windows.rar">下载 ⬇</a></span></p>
<hr>
<h3 id="Lentoid-Linux版H-265-HEVC编码器"><a href="#Lentoid-Linux版H-265-HEVC编码器" class="headerlink" title="Lentoid Linux版H.265/HEVC编码器"></a>Lentoid Linux版H.265/HEVC编码器</h3><p>最新版本：2.8 r6740版本     发布日期：2019/02/26     软件大小：1.45 MB<br>版本说明：1、该版本仅供测试使用，可编码的帧数有上限；2、支持多种码率控制算法，支持4Kx2K视频编码<br>配置要求：2G以上内存；需要支持AVX2指令集；支持系统Centos, Ubuntu等 <span style="float:right"><a href="lentenc_linux.rar">下载 ⬇</a></span></p>
<hr>
]]></content>
  </entry>
  <entry>
    <title>深度学习与智慧教育</title>
    <url>/dpedu/index.html</url>
    <content><![CDATA[<h2 id="原生数据"><a href="#原生数据" class="headerlink" title="原生数据"></a>原生数据</h2><p>实验室已有采集到的原生数据：原生题目、学生笔迹、批改分数等，实验室目前正在基于原生数据进行数据分析、信息挖掘等研究内容。</p>
<p><img src="/dpedu/index/data.png" alt="数据集"></p>
<h2 id="研究方向"><a href="#研究方向" class="headerlink" title="研究方向"></a>研究方向</h2><h3 id="知识追踪"><a href="#知识追踪" class="headerlink" title="知识追踪"></a>知识追踪</h3><p>知识追踪通过学生过往做题情况来刻画其相应知识点掌握程度，进而对学生未来的做题表现进行预测。研究室对知识追踪任务进行了深入研究，已有初步研究成果。研究室提出利用对抗训练来增强模型的泛化能力，有效提升了追踪效果，相应成果已被多媒体领域国际顶级会议ACM MM 2021收录（Oral）。</p>
<div align="center" width="80%">
    <img width="70%" src="/dpedu/index/KnowledgeTracing.png">
    知识追踪图示
</div>

<h3 id="自动批改"><a href="#自动批改" class="headerlink" title="自动批改"></a>自动批改</h3><p>当前原生教育领域的作业、考试均以人工批改为主，人工批改耗时耗力，效率低下。实验室利用收集到的数据进行学生笔迹识别、题目自动批改等相关研究。由于手写笔迹具有高噪音、多风格、不规整等特性，直接进行识别的正确率无法到达批改场景的应用门槛。本方向致力于研究智能化批改技术，解放老师双手。</p>
<div align="center" width="80%">
    <img width="70%" src="/dpedu/index/pigai.png">
    自动批改图示
</div>

<h3 id="图文纠错"><a href="#图文纠错" class="headerlink" title="图文纠错"></a>图文纠错</h3><p>目前教育领域的题目资源分散，题目的数字化存储是建立题库、资源共享的前提基础。采用文本扫描识别技术（OCR）可以大大减少题目数字化的负担，但在实际应用中，OCR系统仍需要辅以人工纠错才能得到确切的文本。本课题将扫描图片和题目文本映射到同一编码空间，对照二者差异生成纠错提示框，探索题目数字化的全自动方法。</p>
<table>
  <tr>
    <th><img width="80%" src="/dpedu/index/jiaodui.png"><div align="center">图文纠错图示</div></th>
    <th><img width="80%" src="/dpedu/index/tuijian.png"><div align="center">题目推荐图示</div></th>
  </tr>
</table>

<h3 id="题目推荐"><a href="#题目推荐" class="headerlink" title="题目推荐"></a>题目推荐</h3><p>目前主流题目推荐方式是根据题目的客观相似度，根据最长匹配子串、关键词、考点标签等计算得出。逻辑上，题目的主观相似度——题目难度也是题目推荐中不可缺少的，而计算主观相似度所需要的学生答题记录较难采集，限制了主观相似度的计算与应用。本项目旨在根据题目特征和学生特征协同过滤相似题目，对任一学生及其在历史题目中的答题效果推荐有针对性的题目集合。</p>
<h3 id="学生建模"><a href="#学生建模" class="headerlink" title="学生建模"></a>学生建模</h3><p>基于学生多维学情大数据为学生建立学情画像，通过横向和纵向等多维对比进行特征分析，对学生的学习能力和习惯进行分类建模，实时预测学生学习状态。</p>
<div align="center" width="100%">
    <img width="80%" src="/dpedu/index/xueqing.png">
    学生建模图示
</div>

<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>实验室还在筹划开设其他和深度学习、智慧教育相关的研究课题。</p>
]]></content>
  </entry>
  <entry>
    <title>视频编解码</title>
    <url>/hevc/index.html</url>
    <content><![CDATA[<h2 id="视频编码标准"><a href="#视频编码标准" class="headerlink" title="视频编码标准"></a>视频编码标准</h2><p>研究室积极参与相关视频编码标准的制定，主导并参与制定多项AVS标准，为我国数字音视频产业发展做出应有贡献。</p>
<div align="center" width="80%">
    （AVS1）《信息技术 先进音视频编码》（GB/T 20090）（主导）
    <img width="70%" src="/hevc/index/1.png">
</div>
<div align="center" width="80%">
    （AVS2）《信息技术 高效多媒体编码》（GB/T 33475）(参与)
    <img width="70%" src="/hevc/index/2.png">
</div>
<div align="center" width="80%">
    AVS团体标准（T/AVS）（参与）
    <img width="70%" src="/hevc/index/3.png">
</div>

<h2 id="广义分布的率失真分析"><a href="#广义分布的率失真分析" class="headerlink" title="广义分布的率失真分析"></a>广义分布的率失真分析</h2><p>率失真理论是信息论的主要分支，其基本问题可以归结如下：对于一个给定的信源分布与失真度量，在特定的码率下能达到的最小期望失真。率失真理论为数据压缩的性能提供理论极限和比较标准，对具体编码方法的研究起到了方向指导作用。研究室深入分析研究了率失真理论，证明了广义高斯分布的率失真函数的导数与分布的缩放参数无关，揭示了其导数值先减小后增大接近6.02 dB/bit的演变规律，进而提出了广义高斯分布达到最优率失真性能的量化模式法则，丰富了研究人员对率失真函数规律的认识外延。相应成果已被国际顶级期刊IEEE TIP以上下篇方式收录，系大陆机构首次。</p>
<div align="center" width="80%">
    <img width="70%" src="/hevc/index/4.png">
    广义高斯分布
</div>

<h2 id="基于率失真分析的编码优化"><a href="#基于率失真分析的编码优化" class="headerlink" title="基于率失真分析的编码优化"></a>基于率失真分析的编码优化</h2><p>研究室基于率失真理论的研究成果对视频编码进行了相关优化研究。不同于以往编码方法通过复杂的模块计算得到码率和失真的关系，研究室以分布估计为主要技术手段，通过广义高斯分布量化的值来估算码率和失真的关系，从而显著减少编码计算量。相应成果已被国际顶级期刊IEEE TCSVT收录。 </p>
<div align="center" width="80%">
    <img width="70%" src="/hevc/index/5.png">
    基于率失真理论的快速高效编码
</div>

<h2 id="高效视频编码的并行优化技术"><a href="#高效视频编码的并行优化技术" class="headerlink" title="高效视频编码的并行优化技术"></a>高效视频编码的并行优化技术</h2><p>当前国际主流编码标准HEVC中使用了大量新的技术，随之引入的是较高的编码复杂度，限制了其在实际场景中的应用。为此，研究室着眼于从不同层次上通过并行技术来加快HEVC的编码速度。在数据级并行层次，研究了HEVC编码中的耗时模块，提出了基于X86平台的数据级并行算法。在任务级并行层次，研究了不同视频内容对并行度的影响，并在波阵面并行处理技术的基础上，分别针对有延迟和低延迟的场景提出了帧间波阵面并行编码方法和基于有向无回图子图的自适应并行框架。相应成果已被国际顶级期刊IEEE TMM、TCSVT收录。</p>
<div align="center" width="80%">
    <img width="70%" src="/hevc/index/6.png">
    数据级并行
</div>
<div align="center" width="80%">
    <img width="70%" src="/hevc/index/7.png">
    任务级并行
</div>

<h2 id="深度学习在环路滤波方面的应用"><a href="#深度学习在环路滤波方面的应用" class="headerlink" title="深度学习在环路滤波方面的应用"></a>深度学习在环路滤波方面的应用</h2><p>由于国际主流编码标准HEVC仍采用基于块的混合编码框架，一些失真效应仍然存在，如方块效应、振铃效应、颜色偏差及图像模糊等。环路滤波作为一种常用于解码端的后处理滤波技术，可有效解决此类问题。针对环路滤波，研究室也有针对性的进行了相关研究。利用深度学习与深度强化学习技术设计了轻量级的环路滤波模块，在提升精度的同时有效降低了模型复杂度，取得了更好的编码效果。相应成果已被国际顶级期刊TIP和TCSVT收录。</p>
<div align="center" width="80%">
    <img width="70%" src="/hevc/index/8.png">
    基于自适应强化学习的环路滤波框架
</div>]]></content>
  </entry>
  <entry>
    <title>专利列表</title>
    <url>/patent/index.html</url>
    <content><![CDATA[<h2 id="已授权专利"><a href="#已授权专利" class="headerlink" title="已授权专利"></a>已授权专利</h2><ul>
<li>孙俊，李睿珩，姚凯，郭宗明. 一种视频资源的调度包截取方法及装置，专利号201010228538.X；</li>
<li>孙俊，李睿珩，邸佩云，胡昌启. 确定调度包优先级的方法和装置，专利号200910203202.5；</li>
<li>孙俊，高文，王悦. 一种SVC视频FGS优先级调度方法，专利号200710176474.1；</li>
<li>高文，孙俊，王悦. 一种基于率失真函数分析模型的SVC平滑重建算法，专利号200710176293.9；</li>
<li>颜乐驹，孙俊，郭宗明，肖建国. 一种双线性两倍上采样方法及系统，专利号201010226016.6；</li>
<li>颜乐驹，孙俊，郭宗明，肖建国. 基于可伸缩视频编码的动态丢包控制方法、系统及装置，专利号ZL201010618196.2；</li>
</ul>
<h2 id="已申请专利"><a href="#已申请专利" class="headerlink" title="已申请专利"></a>已申请专利</h2><ul>
<li>姚凯，孙俊，郭宗明，肖建国. 一种SVC编码方法和编码器，申请号201010217945.0；</li>
<li>陈科吉，孙俊，段一舟，郭宗明. 一种残差预测的确定方法及系统，申请号201110369205.3；</li>
<li>陈科吉，孙俊，段一舟，郭宗明. 一种视频编码方法及系统，申请号201110390580.6；</li>
<li>孙俊，王一磊，陈科吉，郭宗明. 基于可伸缩视频编码的控制视频质量波动的方法及装置，申请号201210001318.2；（已申请PCT；国际申请号：PCT/CN2013/070029）</li>
<li>陈科吉，孙俊，李江涛，段一舟，郭宗明. 一种视频图像编码中的码率控制方法及装置，申请号201310219528.3；</li>
<li>周燕萍，段一舟，孙俊，郭宗明；视频码率调整方法和装置；申请号：201410410143.X；申请日期：2014年8月20日</li>
<li>孟胜彬，孙俊，段一舟，郭宗明；视频质量控制方法和装置；申请号：201410428958.0；申请日期：2014年8月29日</li>
<li>王杰西，孟胜彬，孙俊，郭宗明；基于WebRTC的交互式直播方法及装置；申请号：201510230757.4；申请日期：2015年05月07日</li>
<li>刘森，孟胜彬，孙俊，郭宗明；视频质量控制方法；申请号：201510231060.9；申请日期：2015年05月08日</li>
<li>林镇安，孟胜彬，孙俊，郭宗明；流媒体音频同步方法及装置；申请号：201610031208.9；申请日期：2016年1月18日</li>
<li>林镇安，张奇，孙俊，郭宗明；视频解码方法及装置；申请号：201610137309.4；申请日期：2016年3月10日</li>
<li>林镇安，张奇，冯伟伦，张樱凡，孙俊，郭宗明；视频解码方法和装置；申请号：201610552127.3；申请日期：2016年7月13日</li>
<li>冯伟伦，林镇安，张樱凡，孙俊，郭宗明；视频解码处理方法及装置；申请号：201610529728.2；申请日期：2016年7月6日</li>
<li>王杰西，孟胜彬，孙俊，郭宗明；基于PID控制的视频直播传输控制方法及系统；申请号：201610121496.7；申请日期：年3月7日</li>
<li>王杰西，钟鸣，孙俊，郭宗明；图片转码方法及系统；申请号：201610122469.1；申请日期：年3月7日</li>
<li>钟鸣, 孙俊, 陈科吉, 郭宗明；多视频转码调度方法及装置；申请号：201710114359.5；申请日期：2017年3月1日</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>北大王选所深度视频实验室招收保研实习生</title>
    <url>/stu/index.html</url>
    <content><![CDATA[<p>北京大学王选所深度视频实验室是在孙俊老师带领下的一支优秀的科研小组。孙老师在视频相关领域的研究有很深厚的积累，在相关的顶级国际期刊会议上发表了许多文章，例如：TCSVT、TIP、ICME、TMM等。在孙老师的带领下，实验室学术氛围浓厚，学生们也在VCIP、MMM、ICC、ICASSP、DCC和ICIP等视频相关期刊会议上发表了多篇文章。</p>
<p>同时，实验室也积极与国际国内大厂展开合作，例如Intel、迅雷、UC、美图、花椒等，进行深度视频相关的产业化工作。在实验室实习的过程中，不仅可以收获工程方面的实践与锻炼，还有机会与企业交流合作，提前接触并了解相关行业，为今后的工作打下基础。</p>
<p>深度视频组将科研学习与工程实践相结合，注重对同学全方面的能力培养，同学们在将来的工作中具有良好的竞争力，毕业时也都收获了心仪的offer。2012届学生毕业后入职美国google，后被高薪挖回YY创业；2015界毕业生段一舟博士获得北京大学优秀博士论文，信科学术十佳称号；2016-2018届毕业生获得爱奇艺、今日头条、快手、HULU等视频公司的special offer，均在高速成长的互联网行业继续从事视频相关工作，而且很多都拿到公司的户口。</p>
<p>目前，孙老师致力于传统视频编码与深度学习技术的结合，正带领学生们进行相关内容的研究，例如基于深度学习的视频主观质量评价，运用深度学习来模拟人眼观看视频的感受，建立一套对视频的评价标准，在学术界与产业界都有很高的研究价值。</p>
<p>不仅如此，如果你对数据挖掘相关方面感兴趣的话，孙老师近期也开展了智慧教育与数据挖掘相关课题研究，并且拥有学生的做题笔记和试题相关数据。下面一些课题供你参考：<br>1）    自动批改：利用深度学习相关知识对学生笔记数据进行识别，并结合最新的文本识别技术进行自动判题打分；<br>2）    图文纠错：将拍照扫描得到的题目文本和照片对照，查找潜在错误区域并标记提示纠错人员；<br>3）    题目推荐：题目关联性分析，以一道给定的题目作为输入，为其在题库中寻找最相关的n道题目作为查询结果返回，主要应用场景是针对错题的同题巩固（举一反三）；<br>4）    拍照搜题：图像识别+题目关联分析，以拍照上传的题目图片作为输入，识别和提取题目关键特征，在题库中检索是否有该题目，否则返回一组最相关的题目供选择；<br>5）    学生建模：基于学生多维学情大数据为学生建立学情画像，进行特征分析，对学生的学习能力和习惯进行分类等等；</p>
<p>不仅如此，实验室气氛也非常好，会经常举行聚会和看电影等活动，并且提供非常不错的津贴。</p>
<h2 id="工作内容："><a href="#工作内容：" class="headerlink" title="工作内容："></a>工作内容：</h2><p>方向一：深度视频<br>1、视频编解码相关知识的学习；<br>2、深度学习相关知识的学习；<br>3、进行编解码器的优化以及深度学习在视频编码上的应用的研究。</p>
<p>方向二：数据挖掘<br>1、学习数据挖掘和深度学习相关知识；<br>2、学习获取数据的相关接口；<br>3、上述智慧教育课题的研究工作，也可以自己提出新想法、新课题。</p>
<h2 id="要求："><a href="#要求：" class="headerlink" title="要求："></a>要求：</h2><p>1.实验室招收实习生：</p>
<ul>
<li>大二或大三信息学院学生或元培学院学生，学习成绩优秀，绩点在3.2以上或具有优秀的科研动手能力。</li>
<li>对科研及应用有热情，对待科研认真负责。</li>
</ul>
<p>2.目前实验室也招收2022统招博士，要求如下：</p>
<ul>
<li>有强烈的自我驱动力，喜欢探索，勤奋刻苦；</li>
<li>具有较强的数学功底和编程基础（Python、Matlab）；</li>
<li>计算机、自动化、控制和电子类等相关专业；</li>
<li>有人工智能相关领域一作高质量期刊论文（如IEEE Trans.汇刊）或会议论文（CCF B类推荐及以上）者优先；</li>
<li>有深度学习建模经验者优先；</li>
<li>符合北京大学招生简章要求，详见: <a href="http://eecs.pku.edu.cn/info/1060/9999.htm；" target="_blank" rel="noopener">http://eecs.pku.edu.cn/info/1060/9999.htm；</a></li>
<li>投递需要附件个人简历+本科、硕士成绩单以及其他能证明科研或学习能力的材料。</li>
</ul>
<p><strong>有兴趣的同学可以发邮件联系我们，请将简历发至邮箱<a href="mailto:jsun@pku.edu.cn">jsun@pku.edu.cn</a></strong></p>
]]></content>
  </entry>
  <entry>
    <title>已发表的论文</title>
    <url>/publication/index.html</url>
    <content><![CDATA[<h2 id="期刊"><a href="#期刊" class="headerlink" title="期刊"></a>期刊</h2><p>[1] Zhijie Huang, Jun Sun, Xiaopeng Guo and Mingyu Shang. One-for-all: An Efficient Variable Convolution Neural Network for In-loop Filter of VVC[J]. IEEE Trans. Circuits and Systems for Video Technology (TCSVT), 2021.<br>[2] Zhijie Huang, Jun Sun, Xiaopeng Guo and Mingyu Shang. Adaptive Deep Reinforcement Learning-Based In-Loop Filter for VVC[J]. IEEE Transactions on Image Processing (TIP), 2021.<br>[3] Shengbin Meng, Jun Sun, Yizhou Duan, and Zongming Guo. Adaptive Video Streaming With Optimized Bitstream Extraction and PID-Based Quality Control[J]. IEEE Transactions on Multimedia, 2016.<br>[4] Keji Chen, Jun Sun, Yizhou Duan, and Zongming Guo, “A Novel Wavefront-Based High Parallel Solution for HEVC Encoding”, Accepted by IEEE Trans. Circuits and Systems for Video Technology (TCSVT), 2015.<br>[5] Yizhou Duan, Jun Sun, Leju Yan, Keji Chen, and Zongming Guo, “Novel Efficient HEVC Decoding Solution on General-purpose Processors”, IEEE Trans. Multimedia (TMM), vol. 16, no. 7, pp. 1915 – 1928, November, 2014.<br>[6] Jun Sun, Yizhou Duan, Jiangtao Li, Jiaying Liu and Zongming Guo, “Rate-distortion analysis of dead-zone plus uniform threshold scalar quantization and its application–part I: fundamental theory,” IEEE Trans. Image Process., 2013.<br>[7] Jun Sun, Yizhou Duan, Jiangtao Li, Jiaying Liu and Zongming Guo, “Rate-distortion analysis of dead-zone plus uniform threshold scalar quantization and its application–part II: two-pass VBR coding for H.264/AVC,” IEEE Trans. Image Process., 2013.<br>[8] Xin Zhao, Jun Sun, Siwei Ma and Wen Gao, “Novel statistical modeling, analysis and implementation of rate-distortion estimation for H.264/AVC coders,” IEEE Trans. Circuits Syst. Video Technol., vol. 20, no. 5, pp. 647-660, May. 2010.<br>[9] Jun Sun, Wen Gao, Debin Zhao, Weiping Li, “On Rate-Distortion Modeling and Extraction of H.264/SVC Fine-Granular Scalable Video,” IEEE Trans. Circuits Syst. Video Technol., pp.1-14, Accepted in Jun. 2008.<br>[10] Jun Sun, Wen Gao, Debin Zhao, Qingming Huang, “Statistical Model, Analysis and Approximation of Rate-Distortion Function in MPEG-4 FGS Videos,” IEEE Trans. Circuits Syst. Video Technol., Vol. 16, No. 4, pp. 535-539, Apr. 2006.</p>
<h2 id="会议"><a href="#会议" class="headerlink" title="会议"></a>会议</h2><h3 id="2021"><a href="#2021" class="headerlink" title="2021"></a>2021</h3><p>[1] Xiaopeng Guo, Zhijie Huang, Jie Gao, Mingyu Shang, Maojing Shu, Jun Sun. Enhancing Knowledge Tracing via Adversarial Training. ACM Multimedia, 2021. Oral. <a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475554" target="_blank" rel="noopener">[PDF]</a> <a href="https://github.com/xiaopengguo/ATKT" target="_blank" rel="noopener">[Code]</a></p>
<h3 id="2015-2020"><a href="#2015-2020" class="headerlink" title="2015~2020"></a>2015~2020</h3><p>[1] Zhijie Huang, Xiaopeng Guo, Mingyu Shang, Jie Gao, Jun Sun. An Efficient QP Variable Convolutional Neural Network Based In-loop Filter for Intra Coding. Data Compression Conference. IEEE, 2020.<br>[2] Y. Li, Z. Huang, J. Sun. An Efficient Encoding Method for Video Compositing in HEVC. 26th International Conference on Multimedia Modeling (MMM2020). Oral<br>[3] Z. Huang, Y. Li, J. Sun. Efficient HEVC Downscale Transcoding Based on Coding Unit Information Mapping. 26th International Conference on Multimedia Modeling (MMM2020). Poster<br>[4] Y. Li, Z. Huang, J. Sun. An Efficient Logo Insertion Method for Video Coding in HEVC IEEE 21st International Workshop on Multimedia Signal Processing 27-29 Sept 2019. Oral<br>[5] Zheng Y, Xu P, Sun J, et al. Gradient Based Interpolation for Intra Angular Prediction in HEVC[C]//Circuits and Systems (ISCAS), 2018 IEEE International Symposium on. IEEE, 2018: 1-5.<br>[6] Yushan Zheng ; Peng Xu ; Jun Sun ; Zongming Guo,Gradient Based Interpolation for Intra Angular Prediction in HEVC 2018 IEEE International Symposium on Circuits and Systems<br>[7] Yunchang Li, Qi Jing, Yingfan Zhang, Jun Sun, Efficient Rate Control Method for Logo Insertion Video Coding in HEVC. IEEE International Conference on Visual Communications and Image Processing VCIP December 9-12, 2018, Taichung, Taiwan<br>[8] Keji ChenJun SunZongming Guo,Dachuan Zhao, A Novel Two-Step Integer-pixel Motion Estimation Algorithm for HEVC Encoding on a GPU, , Accepted by MultiMedia Modeling 23rd International Conference(MMM 2017). Oral<br>[9] Wang J, Lei W, Xu P, et al. Adaptive media playout buffer management for latency optimization of mobile live streaming[C]//Multimedia &amp; Expo Workshops (ICMEW), 2017 IEEE International Conference on. IEEE, 2017: 369-374. Oral<br>[10] Jing Q, Xu P, Sun J, et al. Efficient Logo Insertion Method for High-Resolution H. 265/HEVC Compressed Video[C]//Pacific Rim Conference on Multimedia. Springer, Cham, 2017: 674-682.<br>[11] Zhang Y, Lin Z, Feng W, et al. A Real-Time Multi-view AVS2 Decoder on Mobile Phone[C]//Pacific Rim Conference on Multimedia. Springer, Cham, 2017: 89-95.<br>[12] Yinfan Zhang, Zhenan Lin, Weilun Feng, Jun Sun, Zongming Guo, A Real-Time Multi-view AVS2 Decoder on Mobile Phone. Pacific Rim Conference on Multimedia, 2017-5:89-95.<br>[13] Keji Chen, Jun Sun, Yizhou Duan, Zongming Guo, A novel wavefront-based high parallel solution for HEVC encoding, Accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT 2016).<br>[14] Shengbin Meng, Jun Sun, Yizhou Duan, Zongming Guo, Adaptive Video Streaming With Optimized Bitstream Extraction and PID-Based Quality Control, Accepted by IEEE Transactions on Multimedia (TMM 2016).<br>[15] Jiexi Wang, Shengbin Meng, Jun Sun, Zongming Guo, A general PID-based rate adaptation approach for TCP-based live streaming over mobile networks, Accepted by IEEE International Conference on Multimedia and Expo (ICME2016). Oral<br>[16] Zhenan Lin, Qi Zhang, Keji Chen, Jun Sun, Zongming Guo, Efficient Arbitrary Ratio Downscale Transcoding for HEVC, Accepted by IEEE International Conference on Visual Communications and Image Processing (VCIP2016). Oral<br>[17] Peng Xu, Keji Chen, Jun Sun, Xiangyang Ji, Zongming Guo, An Adaptive Intra-Frame Parallel Method based on Complexity Estimation for HEVC, Accepted by IEEE International Conference on Visual Communications and Image Processing (VCIP2016). Oral</p>
<h3 id="2015及以前"><a href="#2015及以前" class="headerlink" title="2015及以前"></a>2015及以前</h3><p>[1] Shengbin Meng, Jun Sun , Zongming Guo, Software Solution for HEVC Encoding and Decoding, International Conference on MultiMedia Modeling (MMM), Sydney, Australia, January 5-7, 2015. Demo<br>[2] Jun Sun, Yizhou Duan, Qi Zhang, Jiasi Shen, Zongming Guo , Towards Rate-Distortion Analysis of General Source Distributions: Property and Principles, Accepted by MMSP 2015. Oral<br>[3] Qi Zhang, Yizhou Duan, Jun Sun , Zongming Guo, A Two-Stage Fast CU Size Decision Method for HEVC Intracoding, Accepted by MMSP 2015. Oral<br>[4] Shengbin Meng, Jun Sun, Yizhou Duan, Zongming Guo , An Efficient Method For No-Reference H.264/SVC Bitstream Extraction, IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Florence, Italy, May 4-9, 2014. Poster<br>[5] Shengbin Meng, Jun Sun , Yilei Wang, Zongming Guo, A PID-based Quality Control Algorithm for SVC Video Streaming, IEEE International Conference on Communications (ICC), Sydney, Australia, June 10-14, 2014. Oral<br>[6] Shengbin Meng, Yizhou Duan, Jun Sun , Zongming Guo, Highly Optimized Implementation of HEVC Decoder for General Processors, IEEE International Workshop on Multimedia Signal Processing (MMSP), Jakarta, Indonesia, September 22-24, 2014. Oral<br>[7] Keji Chen, Yizhou Duan, Jun Sun, Zongming Guo , Towards Efficient Wavefront Parallel Encoding of HEVC: Parallelism Analysis and Improvement, IEEE International Workshop on Multimedia Signal Processing (MMSP), Jakarta, Indonesia, September 22-24, 2014. Oral<br>[8] Yanping Zhou, Yizhou Duan, Jun Sun and Zongming Guo, Proportional Feedback Based Rate Control for Intra Frame of H.164/AVC High Profile, Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA), Siem Reap, City of Angkor Wat, Cambodia, December 9-12, 2014. Oral<br>[9] Yanping Zhou, Yizhou Duan, Jun Sun and Zongming Guo, Towards Simple and Smooth Rate Adaption for VBR Video in DASH, Visual Communications and Image Processing (VCIP), Valletta, Malta, December 7-10, 2014. Oral<br>[10] Jun Sun , Yanping Zhou, Yizhou Duan and Zongming Guo, A Low-latency Peer-to-Peer Live and VOD Streaming System Based on Scalable Video Coding, Visual Communications and Image Processing (VCIP), Valletta, Malta, December 7-10, 2014. Demo<br>[11] Yizhou Duan, Jun Sun, Zongming Guo , Rate-quantization and Distortion-quantization Models of Dead-zone Plus Uniform Threshold Scalar Quantizers for Generalized Gaussian Random Variables, 19th International Conference on Mutimedia Modeling(MMM), Huangshan, Anhui, China, January 7-9, 2013.<br>[12] Yizhou Duan, Jun Sun and Zongming Guo, “Rate-distortion analysis and modeling of dead-zone plus uniform threshold scalar quantization for generalized Gaussian random variables,” in Proc. Data Compression Conference (DCC), Snowbird, Utah, USA, Apr. 2012.<br>[13] Yizhou Duan, Jun Sun and Zongming Guo, “Novel rate-distortion modeling for H.264/AVC and its application in two-pass VBR coding,” Accepted by IEEE International Symposium on Circuits and Systems (ISCAS), Seoul, Korea, May. 2012.<br>[14] Wenyao Zhang, Jun Sun, Jiaying Liu and Zongming Guo, “Optimized bit extraction of SVC exploiting linear error model,” Accepted by IEEE International Symposium on Circuits and Systems (ISCAS), Seoul, Korea, May. 2012.<br>[15] Leju Yan, Jun Sun, Yizhou Duan, Zongming Guo, Implementation of HEVC decoder on x86 processors with SIMD optimization, IEEE Visual Communications and Image Processing Conference(VCIP), San Diego, CA, USA, Nov. 27-30, 2012.<br>[16] Leju Yan, Yizhou Duan, Jun Sun and Zongming Guo, “An optimized real-time multi-thread HEVC decoder,” in Proc. IEEE Visual Communication and Image Processing (VCIP), San Diego, USA, Nov. 2012. (Demo)<br>[17] Keji Chen, Yizhou Duan, Leju Yan, Jun Sun and Zongming Gu, Efficient SIMD Optimization of HEVC Encoder over X86 Processors, Asia Pacific Signal and Information Processing Association Annual Summit and Conference(APSIPA), Hollywood, CA, USA, Dec. 3-6, 2012.<br>[18] Yizhou Duan, Jun Sun, Jiaying Liu and Zongming Guo, “Efficient dead-zone plus uniform threshold scalar quantization of generalized Gaussian random variables,” in Proc. IEEE Visual Communication and Image and Processing (VCIP), Tainan, Taiwan, Nov. 2011.<br>[19] Ruiheng Li, Jun Sun and Wen Gao, “Fast Weighted Algorithms for Bitstream Extraction of SVC Medium-Grain Scalable Video Coding”. Proc. IEEE International Conference on Multimedia &amp; Expo (ICME 2010), Singapore, Jun. 2010.<br>[20] Xin Zhao, Jun Sun, Wen Gao, “A Novel Rate Estimation Model for Mode Decision of H.264/AVC,” in Proc. of SPIE Visual Communications and Image Processing (VCIP), San Jose, California USA, Jan. 2009.<br>[21] Zhenyu Wang, Luhong Liang, Xianguo Zhang, Jun Sun, Debin Zhao, Wen Gao, “A Novel Macro-Block Group Scheme of AVS Coding for Many-Core Processor,” in Proceedings of IEEE Pacific-Rim Conference International Conference on Multimedia, PCM2009, Bangkok,Thailand, Dec.2009<br>[22] Jun Sun, Wen Gao, Debin Zhao, “Smooth Extraction of SVC Fine-Granular SNR Scalable Videos with a Virtual-GOP-Based Rate-Distortion Modeling,” in Proc. of SPIE Visual Communications and Image Processing (VCIP), San Jose, California USA, Jan. 2008.<br>[23] Yue Wang, Jun Sun, Siwei Ma, Wen Gao, “Theoretic Analysis of Inter Frame Dependency in Video Coding,” in Proc. of Pacific-Rim Conference on Multimedia (PCM), Dec. 2008.<br>[24] Jun Sun, Wen Gao, Debin Zhao, “Statistical Analysis and Modeling of Rate-Distortion Function in SVC Fine-Granular SNR Scalable Videos,” in Proc. of IEEE International Conference on Multimedia &amp; Expo (ICME), Beijing, China, Jul. 2007.<br>[25] Jun Sun, Wen Gao, Debin Zhao, “Rate-Distortion Modeling and it’s Application to Quality Layer Assignment in SVC Fine-Granular SNR Scalable Videos,” in Proc. of Picture Coding Symposium (PCS), Lisbon, Portugal, Nov. 2007.<br>[26] Jianfei Huang, Jun Sun, Wen Gao, “A Novel Two-Pass VBR Coding Algorithm for the H.264/AVC Video Coder Based on a New Analytical R-D Model,” in Proc. of IEEE Picture Coding Symposium (PCS), Lisbon, Portugal, 2007.<br>[27] Da Liu, Debin Zhao, Jun Sun, Wen Gao, “Direct Mode Coding for B Pictures Using Virtual Reference,” in Proc. of IEEE International Conference on Multimedia &amp; Expo (ICME), Beijing, China, 2007.<br>[28] Jun Sun, Wen Gao, Debin Zhao, Qingming Huang, “A Simple Algorithm for Constant Quality Reconstruction of Scalable Video Using a New Analytical R-D Model,” in Proc. of IEEE Picture Coding Symposium (PCS), Beijing, China, Apr. 2006.<br>[29] Jun Sun, Wen Gao, Debin Zhao, Qingming Huang, “Statistical Model, Analysis and Approximation of Rate-Distortion Function in MPEG-4 FGS Videos,” in Proc. of Visual Communications and Image Processing (VCIP), SPIE Press, Beijing, China, Jul. 2005.<br>[30] Jun Sun, Wen Gao, Qingming Huang, “A Novel FGS Base-Layer Encoding Model And Weight-Based Rate Adaptation for Constant-Quality Streaming,” in Proc. of International Conference on Image and Graphics (ICIG), HongKong, Dec. 2004.</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/activities/zhijie_TCSVT.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/activities/zhijie_tcsvt1.html</url>
    <content><![CDATA[<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
<meta name="generator" content="Hexo 4.2.1"></head>
<body>
<h3 style="text-align:center">One-for-all: An Efficient Variable Convolution
    Neural Network for In-loop Filter of VVC</h3>
<h4 style="text-align:center">Zhijie Huang, Jun Sun, Xiaopeng Guo and Mingyu Shang</h4>
<img src="/activities/zhijie_tcsvt1.htm/zhijie_tcsvt.png" style="width: 800px;">
<h4>Abstract：</h4>Recently, many researches on convolution neural
network (CNN) based in-loop filters have been proposed to
improve coding efficiency. However, most existing CNN based
filters tend to train and deploy multiple networks for various
quantization parameters (QP) and frame types (FT), which
drastically increases resources in training these models and the
memory burdens for video codec. In this paper, we propose a
novel variable CNN (VCNN) based in-loop filter for VVC, which
can effectively handle the compressed videos with different QPs
and FTs via a single model. Specifically, an efficient and flexible
attention module is developed to recalibrate features according to
QPs or FTs. Then we embed the module into the residual block
so that these informative features can be continuously utilized in
the residual learning process. To minimize the information loss in
the learning process of the entire network, we utilize a residual
feature aggregation module (RFA) for more efficient feature
extraction. Based on it, an efficient network architecture VCNN
is designed that can not only effectively reduce compression
artifacts, but also can be adaptive to various QPs and FTs.
To address training data imbalance on various QPs and FTs
and improve the robustness of the model, a focal mean square
error loss function is employed to train the proposed network.
Then we integrate the VCNN into VVC as an additional tool of
in-loop filters after the deblocking filter. Extensive experimental
results show that our VCNN approach obtains on average 3.63%,
4.36%, 4.23%, 3.56% under all intra, low-delay P, low-delay, and
random access configurations, respectively, which is even better
than QP-Separate models.
<br>
文章已被IEEE TCSVT收录，<a href="https://ieeexplore.ieee.org/document/9455379" target="_blank" rel="noopener"><strong>了解更多</strong></a>。
</body>

</html>]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/activities/xiaopeng_mm1.html</url>
    <content><![CDATA[<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
<meta name="generator" content="Hexo 4.2.1"></head>
<body>
<h3 style="text-align:center">Enhancing Knowledge Tracing via Adversarial Training</h3>
<h4 style="text-align:center">Xiaopeng Guo, Zhijie Huang, Jie Gao, Mingyu Shang, Maojing Shu, Jun Sun</h4>
<img src="/activities/xiaopeng_mm1.htm/xiaopeng_mm.png" style="width: 800px;">
<h4>Abstract：</h4>
We study the problem of knowledge tracing (KT) where the goal
is to trace the students’ knowledge mastery over time so as to
make predictions on their future performance. Owing to the good
representation capacity of deep neural networks (DNNs), recent
advances on KT have increasingly concentrated on exploring DNNs
to improve the performance of KT. However, we empirically reveal
that the DNNs based KT models may run the risk of overfitting,
especially on small datasets, leading to limited generalization. In
this paper, by leveraging the current advances in adversarial training (AT), we propose an efficient AT based KT method (ATKT)
to enhance KT model’s generalization and thus push the limit of
KT. Specifically, we first construct adversarial perturbations and
add them on the original interaction embeddings as adversarial
examples. The original and adversarial examples are further used
to jointly train the KT model, forcing it is not only to be robust to
the adversarial examples, but also to enhance the generalization
over the original ones. To better implement AT, we then present
an efficient attentive-LSTM model as KT backbone, where the key
is a proposed knowledge hidden state attention module that adaptively aggregates information from previous knowledge hidden
states while simultaneously highlighting the importance of current
knowledge hidden state to make a more accurate prediction. Extensive experiments on four public benchmark datasets demonstrate
that our ATKT achieves new state-of-the-art performance. Code is
available at: https://github.com/xiaopengguo/ATKT.
<br>
文章已被ACM MM收录，<a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475554" target="_blank" rel="noopener"><strong>了解更多</strong></a>。
</body>

</html>]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/activities/zhijie_tip1.html</url>
    <content><![CDATA[<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
<meta name="generator" content="Hexo 4.2.1"></head>
<body>
<h3 style="text-align:center">Adaptive Deep Reinforcement Learning-Based In-Loop Filter for VVC</h3>
<h4 style="text-align:center">Zhijie Huang, Jun Sun, Xiaopeng Guo and Mingyu Shang</h4>
<img src="/activities/zhijie_tip1.htm/zhijie_tip.png" style="width: 800px;">
<h4>Abstract：</h4>Deep learning-based in-loop filters have recently
demonstrated great improvement for both coding efficiency and
subjective quality in video coding. However, most existing deep
learning-based in-loop filters tend to develop a sophisticated
model in exchange for good performance, and they employ a
single network structure to all reconstructed samples, which lack
sufficient adaptiveness to the various video content, limiting their
performances to some extent. In contrast, this paper proposes an
adaptive deep reinforcement learning-based in-loop filter (ARLF)
for versatile video coding (VVC). Specifically, we treat the
filtering as a decision-making process and employ an agent to
select an appropriate network by leveraging recent advances in
deep reinforcement learning. To this end, we develop a lightweight
backbone and utilize it to design a network set S containing
networks with different complexities. Then a simple but efficient
agent network is designed to predict the optimal network from
S, which makes the model adaptive to various video contents.
To improve the robustness of our model, a two-stage training
scheme is further proposed to train the agent and tune the
network set. The coding tree unit (CTU) is seen as the basic
unit for the in-loop filtering processing. A CTU level control flag
is applied in the sense of rate-distortion optimization (RDO).
Extensive experimental results show that our ARLF approach
obtains on average 2.17%, 2.65%, 2.58%, 2.51% under allintra, 
low-delay P, low-delay, and random access configurations,
respectively. Compared with other deep learning-based methods,
the proposed approach can achieve better performance with low
computation complexity.
<br>
文章已被TIP2021收录，<a href="https://ieeexplore.ieee.org/document/9446562" target="_blank" rel="noopener"><strong>了解更多</strong></a>。
</body>

</html>]]></content>
  </entry>
  <entry>
    <title>科研项目</title>
    <url>/project/index.html</url>
    <content><![CDATA[<p>[1] 国家自然科学基金委员会，面上项目，62071014，多聚焦视频的融合与编码研究，2020-01至2023-12，55万元，在研，主持<br>[2] 国家自然科学基金委员会，面上项目，61671025，立体视频的高效编码研究，2017-01至2020-12，60万元，已结题，主持<br>[3] 国家科技部，国家高技术研究发展计划（863 计划），2015AA011605，真三维视频 紧凑表示与高效压缩，2015-01至2018-12，申请人经费130万元，已结题，参加<br>[4] 教育部，“新世纪优秀人才支持计划”项目，NCET-13-0008，下一代可伸缩视频的 率失真分析研究及其应用，2014-01至2016-12，50万元，已结题，主持<br>[5] 国家自然科学基金委员会，面上项目（青年-面上直通车项目），61271020，高效 可伸缩视频的编码、分析和调度研究，2013-01至2016-12，80万元，已结题，主持<br>[6] 国家自然科学基金委员会，面上项目，61071082，异构网络中可伸缩视频与压缩感 知联合编码研究，2011-01至2013-12，已结题，参加<br>[7] 北京市科学技术研究院，“北京市科技新星计划”项目，2010B001，面向三网融合 的可伸缩视频编码与传输系统研究，2010-12至2013-12，20万元，已结题，主持<br>[8] 国家自然科学基金委员会，青年基金项目，60902004，面向3G的可伸缩视频编码、 分析和调度研究，2010-01至2012-12，22万元，已结题，主持<br>[9] 北京市科学技术委员会，面上项目，4102025，可伸缩视频编码和调度研究，201001至2012-12，11万元，已结题，主持<br>[10] 国家自然科学基金委员会，重点项目，60833013，基于视觉特性的高效编码研究， 2009-01至2012-12，申请人经费20万元，已结题，参加<br>[11] 国家科技部，973计划，2009CB320900，基于视觉特性的视频编码理论与方法研究 ，2009-01至2013-12，申请人经费50万元，已结题，参加<br>[12] 中国博士后科学基金委员会，一等资助项目，20060400030，基于AVS的转码系统 及其新技术，2006-09至2008-09，5万元，已结题，主持</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/activities/2021-09-26.html</url>
    <content><![CDATA[<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
<meta name="generator" content="Hexo 4.2.1"></head>
<body>
<h3>实验室聚餐 雪中鲜鱼村</h3>
<img src="/activities/2021-09-26.htm/jucan20210926.jpg" style="width: 500px;">
</body>
</html>]]></content>
  </entry>
</search>
